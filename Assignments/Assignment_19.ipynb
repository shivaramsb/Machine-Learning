{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Why is it necessary to investigate data? Is there a discrepancy in how qualitative and quantitative data are explored?**"
      ],
      "metadata": {
        "id": "ozbVn62qfqgv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Investigating data is necessary to understand its characteristics, detect anomalies, identify patterns, and prepare it for modeling. It helps ensure data quality and informs the selection of appropriate models and algorithms.\n",
        "\n",
        "* Quantitative Data: Typically explored using statistical measures (mean, median, variance) and visualizations (histograms, scatter plots) to understand distribution, central tendency, and variability.\n",
        "* Qualitative Data: Explored using thematic analysis, coding, and categorization to identify patterns, themes, and relationships. Visualizations like bar charts and word clouds may be used.\n",
        "\n",
        "The approach to exploring qualitative and quantitative data differs due to their inherent nature, with qualitative data focusing on non-numeric insights and quantitative data on numeric analysis."
      ],
      "metadata": {
        "id": "gzFDEKo0fqlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.  What is the definition of a target function? In the sense of a real-life example, express the target function. How is a target function's fitness assessed?**"
      ],
      "metadata": {
        "id": "PGBQB9QYfqpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target Function: In machine learning, the target function (often denoted as\n",
        "ùëì\n",
        "f) is the function that the model aims to approximate. It maps input features (X) to output labels (Y).\n",
        "Real-Life Example: In predicting house prices, the target function could be\n",
        "ùëì\n",
        "(\n",
        "features\n",
        ")\n",
        "=\n",
        "price\n",
        "f(features)=price, where features include size, location, number of rooms, etc.\n",
        "Fitness Assessment: The fitness of a target function is assessed using evaluation metrics such as Mean Squared Error (MSE), Mean Absolute Error (MAE), or R-squared for regression tasks, and accuracy, precision, recall, F1 score, or AUC-ROC for classification tasks."
      ],
      "metadata": {
        "id": "4ebUsRCqfqsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.  What are predictive models, and how do they work? What are descriptive types, and how do you use them? Examples of both types of models should be provided. Distinguish between these two forms of models.**"
      ],
      "metadata": {
        "id": "U35I4jDmfqwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Predictive Models: These models predict outcomes based on input data. They learn patterns from historical data to make predictions on new, unseen data. Examples include regression models predicting house prices and classification models predicting whether an email is spam.\n",
        "* Descriptive Models: These models identify patterns or relationships within the data but do not predict outcomes. They are used to understand data and generate insights. Examples include clustering models grouping customers based on behavior and association rule mining in market basket analysis.\n",
        "\n",
        "Distinction:\n",
        "\n",
        "* Purpose: Predictive models forecast future outcomes; descriptive models explain relationships and patterns.\n",
        "* Examples: Predictive - Linear regression for house prices, Logistic regression for spam detection; Descriptive - K-means clustering for customer segmentation, Apriori algorithm for market basket analysis."
      ],
      "metadata": {
        "id": "goRM3ViUfqzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Describe the method of assessing a classification model's efficiency in detail. Describe the various measurement parameters.**"
      ],
      "metadata": {
        "id": "Odqj2q9HgYKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assessing a classification model's efficiency involves using several evaluation metrics:\n",
        "\n",
        "* Accuracy: The ratio of correct predictions to total predictions.\n",
        "Precision: The ratio of true positive predictions to the total positive predictions made by the model.\n",
        "* Recall (Sensitivity): The ratio of true positive predictions to the total actual positives.\n",
        "* F1 Score: The harmonic mean of precision and recall.\n",
        "* AUC-ROC: The area under the ROC curve, which plots the true positive rate against the false positive rate.\n",
        "* Confusion Matrix: A table showing the true positives, true negatives, false positives, and false negatives."
      ],
      "metadata": {
        "id": "BXenlsftgYQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Is it possible to boost the efficiency of a learning model? If so, please clarify how.**"
      ],
      "metadata": {
        "id": "UQwjselDgYUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, it is possible to boost the efficiency of a learning model through various techniques:\n",
        "\n",
        "* Feature Engineering: Creating new features or modifying existing ones to provide more relevant information to the model.\n",
        "* Regularization: Adding a penalty to the model's complexity (e.g., L1 or L2 regularization) to prevent overfitting.\n",
        "* Hyperparameter Tuning: Optimizing model hyperparameters using techniques like grid search or random search.\n",
        "* Ensemble Methods: Combining multiple models (e.g., bagging, boosting, stacking) to improve performance.\n",
        "* Cross-Validation: Using cross-validation to ensure that the model generalizes well to unseen data.\n",
        "* Data Augmentation: Increasing the diversity of the training data by applying transformations (especially useful in image and text data)."
      ],
      "metadata": {
        "id": "kuxmiu6cgYb-"
      }
    }
  ]
}