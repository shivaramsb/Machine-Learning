{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. What kind of learning algorithm makes predictions using a similarity measure?**"
      ],
      "metadata": {
        "id": "hA-9hz-yDKc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The K-Nearest Neighbors (KNN) algorithm makes predictions using a similarity measure. It classifies new data points based on the majority class among its K nearest neighbors in the feature space, using distance metrics such as Euclidean distance.\n",
        "\n"
      ],
      "metadata": {
        "id": "wg0DgCIiDKlF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What's the difference between a model parameter and a hyperparameter in a learning algorithm?**"
      ],
      "metadata": {
        "id": "KHmIEcRODKuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Model Parameters: These are internal parameters learned by the algorithm during training, such as the weights in a linear regression model or the split points in a decision tree.\n",
        "* Hyperparameters: These are external configurations set by the user before training, which control the learning process, such as the learning rate in gradient descent or the number of trees in a random forest. Hyperparameters are not learned from the data but are tuned to achieve the best model performance."
      ],
      "metadata": {
        "id": "CcilrtknDKyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.  What are the criteria that model-based learning algorithms look for? What is the most popular method they use to achieve success? What method do they use to make predictions?**"
      ],
      "metadata": {
        "id": "kWbTX5bFDK1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Criteria: Model-based learning algorithms look for patterns in the data that generalize well to new, unseen data. They aim to minimize a cost function that measures the difference between the predicted and actual values.\n",
        "* Popular Method: The most popular method used to achieve success is gradient descent, which iteratively adjusts the model parameters to minimize the cost function.\n",
        "* Prediction Method: These algorithms use the learned model parameters to make predictions on new data. For example, in linear regression, the model uses the learned weights to predict the target variable for new input data."
      ],
      "metadata": {
        "id": "3gaw3bxpDK4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Can you name four of the most important Machine Learning challenges?**"
      ],
      "metadata": {
        "id": "D2oGBm_jDK73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Data Quality and Quantity: Obtaining sufficient and high-quality data for training.\n",
        "* Model Interpretability: Understanding and explaining how complex models make decisions.\n",
        "* Overfitting and Underfitting: Balancing model complexity to achieve good generalization.\n",
        "* Scalability: Ensuring models can handle large-scale data and computations efficiently."
      ],
      "metadata": {
        "id": "HXaUbHS2DK-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What happens if the model performs well on the training data but fails to generalize the results to new situations? Can you think of three different options?**"
      ],
      "metadata": {
        "id": "rHiRoazODLB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If a model performs well on training data but fails to generalize to new data, it is likely overfitting. Three options to address this are:\n",
        "\n",
        "* Regularization: Adding a penalty for larger model coefficients to prevent overfitting.\n",
        "* Cross-Validation: Using techniques like k-fold cross-validation to ensure the model generalizes well.\n",
        "* Simplify the Model: Reducing the complexity of the model by decreasing the number of features or parameters."
      ],
      "metadata": {
        "id": "WCDnvCM9DLFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.What exactly is a test set, and why would you need one?**"
      ],
      "metadata": {
        "id": "trwihDG-DLIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A test set is a separate portion of the data that is not used during training but is reserved to evaluate the final performance of the model. It provides an unbiased estimate of the model's accuracy and generalization to new, unseen data."
      ],
      "metadata": {
        "id": "iW1l7PnZDLLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What is a validation set's purpose?**"
      ],
      "metadata": {
        "id": "Y_S775Y4DLOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A validation set is used to tune hyperparameters and make decisions about model selection. It helps prevent overfitting by providing a performance measure during the model development phase, allowing for iterative adjustments without using the test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "4neAhuolDLRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. What precisely is the train-dev kit, when will you need it, how do you put it to use?**"
      ],
      "metadata": {
        "id": "1Zo41wUrDLUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A train-dev set (also called a development set) is used when working with very large datasets to further ensure that model selection and hyperparameter tuning do not lead to overfitting. It is a subset of the training data, separated from the main training set, and used to validate the model before final testing. You use it by training on the training set, validating on the train-dev set, and making final evaluations on the test set."
      ],
      "metadata": {
        "id": "Lb-N2thRE04N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. What could go wrong if you use the test set to tune hyperparameters?**"
      ],
      "metadata": {
        "id": "5E3TVcaQE00e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the test set to tune hyperparameters can lead to data leakage, where the model indirectly learns from the test data, leading to overly optimistic performance estimates. This undermines the test set's role as an unbiased evaluation of the model's generalization ability and can result in a model that performs poorly on truly unseen data."
      ],
      "metadata": {
        "id": "Jk2yuF9BE0vw"
      }
    }
  ]
}